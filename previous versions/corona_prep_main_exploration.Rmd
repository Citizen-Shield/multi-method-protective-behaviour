---
title: "Corona prepping using Finnish data Decision Trees"
author: "James Twose"
output: html_notebook
---

Main question: at this point we're interested in one single classification, i.e. what predicts whether people do maskless contacts with non-householders

[Research Document](https://docs.google.com/document/d/1iLciHcvVvf8QwFS7wiyNBevpD1B9yDRqMlM4_oCcVcA/edit?usp=sharing)

[Questions codebook](https://docs.google.com/document/d/1YZVCP1UNxnNLAK2kYDfA9Y98leTZYurZD-d8iByhdi0/edit?usp=sharing)

[Method of delivery](https://docs.google.com/document/d/1G1JT9JUJrTK3aaXXuRawYACJaGNxU7mcXL9i-d8eKXY/edit)

```{r, echo=FALSE, message=FALSE}
library(ggplot2)
library(parsnip)
library(dplyr)
library(faux)
library(DataExplorer)
library(caret)
library(randomForest)
library(tidyr)
library(cvms)
library(doParallel)
library(rattle)
library(rpart)
```

```{r}
sessionInfo()
```


```{r}
df <- read.csv("data/shield_gjames_21-06-10.csv")
```

```{r}
grouping_var <- "behaviour_unmasked"
# feature_list <- colnames(df[, !(names(df) %in% c(grouping_var, "id"))])
feature_list <- c('intention_indoor_meeting', 'norms_people_present_indoors',
       'sdt_motivation_extrinsic_2', 'sdt_motivation_identified_4', 'norms_family_friends', 'norms_risk_groups', 'norms_officials',
       'norms_people_present_indoors')
```

```{r}
if (grouping_var == "behaviour_unmasked") {
  # df <- df %>% mutate(tmp = if_else(!!as.symbol(grouping_var) != 5, 'bad', 'good'))
  df <- df %>% mutate(tmp = if_else(!!as.symbol(grouping_var) != 5, 0, 1))

  names(df)[names(df) == 'tmp'] <- paste0(grouping_var, "_bool")
}
    
```

```{r}
df[, paste0(grouping_var, "_bool")] <- as.factor(df[, paste0(grouping_var, "_bool")])
```


```{r, fig.height=15, fig.width=15}
# Exploratory data analysis
plot_intro(df)
plot_bar(df)
plot_correlation(df)
```


```{r}
head(df[, c(paste0(grouping_var, "_bool"), grouping_var)])
```

```{r}
y <- df[, paste0(grouping_var, "_bool")]
# X <- df[, feature_list]
```

```{r}
decision_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("classification") %>% 
  translate()
```

```{r}
feature_list
paste(unlist(feature_list), collapse='+')
as.symbol(paste(unlist(feature_list), collapse='+'))
```


```{r}
# decision_tree(
#   mode = "classification",
#   cost_complexity = NULL,
#   tree_depth = NULL,
#   min_n = NULL
# ) %>% 
#   set_engine("rpart") %>% 
#   fit(behaviour_unmasked ~ intention_indoor_meeting+norms_people_present_indoors, data=df)
```

```{r}
set.seed(2021)
fit <- rpart::rpart(behaviour_unmasked_bool ~ intention_indoor_meeting+norms_people_present_indoors+sdt_motivation_extrinsic_2+sdt_motivation_identified_4+norms_family_friends+norms_risk_groups+norms_officials+norms_people_present_indoors, data=df)
fit
```

```{r, fig.height=10, fig.width=15}
# plot(fit)
# text(fit, use.n = TRUE)
```

```{r, fig.height=10, fig.width=15}
fancyRpartPlot(fit)
```


# Running random forests to classify the boolean target

```{r}
# Define the control using a random forest selection function
control <- rfeControl(functions = rfFuncs, # random forest
                      method = "repeatedcv", # or just cv
                      repeats = 10, # number of repeats
                      number = 10) # the number of folds
```

```{r}
x <- df %>%
  select(-behaviour_unmasked_bool, -behaviour_unmasked, -id) %>%
  as.data.frame()

y <- df$behaviour_unmasked_bool
```

```{r}
set.seed(2021)
inTrain <- createDataPartition(y, p = .80, list = FALSE)[,1]

x_train <- x[ inTrain, ]
x_test  <- x[-inTrain, ]

y_train <- y[ inTrain]
y_test  <- y[-inTrain]

colnames(x_train)
```

```{r}
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

set.seed(2021)
# Run RFE
result_rfe1 <- rfe(x = x_train, 
                   y = y_train, 
                   sizes = c(1:20), 
                   rfeControl = control)

stopCluster(cl)
```

```{r}
# Print the results
result_rfe1
```


```{r}
# Predictors
predictors(result_rfe1)
```


```{r}
# Variable importance
varImp(result_rfe1)
```


```{r, fig.height=12, fig.width=20}
varimp_data <- data.frame(feature = row.names(varImp(result_rfe1)),
                          importance = varImp(result_rfe1)[, 1])

ggplot(data = varimp_data, 
       aes(x = importance, y = reorder(feature, -importance), fill = feature)) +
  geom_bar(stat="identity") + labs(x = "Features", y = "Variable Importance") + 
  geom_text(aes(label = round(importance, 2)), hjust=1.6, vjust=1.6, color="white", size=4) + 
  theme_bw() + theme(legend.position = "none")

# ggsave("images/Random_forest_feature_importance_w_RFE.png", dpi = 400, height = 12, width = 20)
```

```{r}
# Visualize the results
ggplot(data = result_rfe1, metric = "Accuracy") + theme_bw()
# ggplot(data = result_rfe1, metric = "Kappa") + theme_bw()
```

```{r}
# Post prediction
postResample(predict(result_rfe1, x_test), y_test)
```


```{r}
data.frame(result_rfe1$fit$confusion)
result_rfe1$fit$confusion
```

```{r}
top_features <- head(varimp_data, 3)$feature
```

```{r}
x <- df[top_features[1:2]]

y <- df$behaviour_unmasked_bool
```

```{r}
set.seed(2021)
inTrain <- createDataPartition(y, p = .80, list = FALSE)[,1]

x_train <- x[ inTrain, ]
x_test  <- x[-inTrain, ]

y_train <- y[ inTrain]
y_test  <- y[-inTrain]

colnames(x_train)
```

```{r}
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

# Run RFE
result_rfe1 <- rfe(x = x_train, 
                   y = y_train, 
                   sizes = c(1:20), 
                   rfeControl = control)

stopCluster(cl)
```


```{r}
# Visualize the results
ggplot(data = result_rfe1, metric = "Accuracy") + theme_bw()
# ggplot(data = result_rfe1, metric = "Kappa") + theme_bw()
```
```{r}
# Post prediction
postResample(predict(result_rfe1, x_test), y_test)
```


```{r}
prediction_tibble <- tibble("target"=y_test,
       "prediction"=predict(result_rfe1, x_test)$pred)
prediction_table <- table(prediction_tibble)
cfm <- as_tibble(prediction_table)
plot_confusion_matrix(cfm, 
                      target_col = "target", 
                      prediction_col = "prediction",
                      counts_col = "n")
```
# Running a single decision tree to classify the boolean target based on the top features identified in the random forest

```{r}
top_features <- head(varimp_data, 3)$feature
```

```{r}
x <- df[top_features[1:2]]

y <- df$behaviour_unmasked_bool
```

```{r}
set.seed(2021)
inTrain <- createDataPartition(y, p = .80, list = FALSE)[,1]

x_train <- x[ inTrain, ]
x_test  <- x[-inTrain, ]

y_train <- y[ inTrain]
y_test  <- y[-inTrain]

colnames(x_train)
```

```{r}
registerDoSEQ()
```


```{r}
# unregister_dopar <- function() {
#   env <- foreach:::.foreachGlobals
#   rm(list=ls(name=env), pos=env)
# }
ctrl <- trainControl(
                     method = "cv", 
                     # repeats = 3, 
                     # savePred=TRUE,
                     # verboseIter = TRUE,
                     # preProcOptions = list(thresh = 0.95)
                    )

# preProcessInTrain<-c("center", "scale")
metric_used<-"Accuracy"
set.seed(2021)
model <- train(
               x=x_train,
               y=y_train,
               method = "rpart",
               trControl = ctrl,
               metric=metric_used,
               # tuneLength = 10,
               # preProc = preProcessInTrain
              )
```


```{r}
# Visualize the results
ggplot(data = model, metric = "Accuracy") + theme_bw()
# ggplot(data = result_rfe1, metric = "Kappa") + theme_bw()
```
```{r}
# Post prediction
postResample(predict(model, x_test), y_test)
```


```{r}
prediction_tibble <- tibble("target"=y_test,
       "prediction"=predict(model, x_test))
prediction_table <- table(prediction_tibble)
cfm <- as_tibble(prediction_table)
plot_confusion_matrix(cfm, 
                      target_col = "target", 
                      prediction_col = "prediction",
                      counts_col = "n")
```

```{r, fig.height=10, fig.width=15}
fancyRpartPlot(model$finalModel)
```


```{r}
pred_df <- data.frame(target=as.numeric(y_test),
           prediction=as.numeric(predict(model, x_test)),
           row.names = rownames(x_test))

pred_df$correct_or_not <- pred_df$target + pred_df$prediction

zero_ids <- rownames(pred_df[pred_df[, "correct_or_not"] == 2,])
one_ids <- rownames(pred_df[pred_df[, "correct_or_not"] == 4,])

length(zero_ids)
length(one_ids)
```

```{r}
df[zero_ids, ]
df[one_ids, ]
```

# Running an ordinal variant of a decision tree (rpartScore) using the top features found, with a grid search CV

```{r}
# Specify 10 fold cross-validation
ctrl_cv <- trainControl(method = "repeatedcv",
                        search="grid",
                        number = 10,
                        repeats=10,
                        timingSamps = 5,
                        # seeds = c(1:101)
                        )
# Predict income using decision tree
dec_mod <- train(x=x_train,
                 y=y_train,
                    method = "rpartScore",  
                    trControl = ctrl_cv,
                    tuneGrid = expand.grid(
                      cp = seq(0,1,0.1),
                      split = c("abs", "quad"),
                      prune = c("mc", "mr")
                      )

                 )
```

```{r}
dec_mod$results
```
