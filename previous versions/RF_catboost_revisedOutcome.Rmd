---
title: "taloustutkimus_RF_catboost"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(catboost)

### The package had to be manually downloaded

# catboost_latest_version <- "0.26"
# devtools::install_url(paste0("https://github.com/catboost/catboost/releases/download/v",
#                              catboost_latest_version,
#                              "/catboost-R-Windows-", 
#                              catboost_latest_version, ".tgz"), 
#                       build_opts = c("--no-multiarch", "--no-test-load"))

# install.packages("C:/rlibs/4.0.5/catboost-R-Windows-0.26.tgz", 
#                  repos = NULL, 
#                  type = "source", 
#                  INSTALL_opts = c("--no-multiarch", "--no-test-load"))


```

# Data preparation

## Read data

```{r}
# df <- haven::read_spss("data/taloustutkimus/24940_Citizen_Shields.sav")
df_eng <- 
  # haven::read_spss("./data/taloustutkimus/gjames_data/shield_gjames_21-07-25.sav")
  # readr::read_rds("../../data/taloustutkimus/gjames_data/shield_gjames_21-09-20.rds")
  read.csv("../../data/taloustutkimus/gjames_data/shield_gjames_21-09-20.csv")

  
varnames_lookup <- 
  read.csv("../../data/taloustutkimus/Citizen Shield notes - Variable names.csv")

vartypes <- data.frame(
  name = varnames_lookup$New.variable.name, 
  type = varnames_lookup$Type)



# cat(unique(vartypes$type), sep = "\n")
# df_eng$risk_contagion_absent_protection %>% attributes()
```


```{r}
###-----------------------------------------------------------------------------
### Load data
###-----------------------------------------------------------------------------

df <- df_eng

###-----------------------------------------------------------------------------
### Create new composite measure of intention and behavior
###-----------------------------------------------------------------------------

intentionVars <-
  grep("^intention_", names(df), value=TRUE);

### Note: intention response options are:
###   1 = I will wear a mask all the time
###   2 = I'm going to wear a mask part of the time
###   3 = I'm not going to wear a mask
###   4 = I'm not going to go at all
###
### We recode these so that the new categories reflect the
### risk due to potential unmasked exposure to SARS-CoV-2:
###   1 -> 0
###   2 -> 1
###   3 -> 2
###   4 -> 0

for (currentIntentionVar in intentionVars) {
  df[, paste0(currentIntentionVar, "_recoded")] <-
    ifelse(
      df[, currentIntentionVar] == 4,
      0,
      df[, currentIntentionVar] - 1
    );
}

df <- df %>% 
  dplyr::mutate(across(.cols = all_of(intentionVars),
                           .fns = ~dplyr::case_when(. == 4 ~ 0,
                                                    TRUE ~ .-1),
                           .names = "{.col}_recoded"))

df$intention_composite <-
  rowSums(df[, paste0(intentionVars, "_recoded")]);

### Behavior

behaviorVars <-
  grep("^behaviour_", names(df), value=TRUE);

behaviorVars_selected <-
  grep("indoors|unmasked", behaviorVars, value=TRUE);

### For these two behavior measures, the response
### options are different:
###
###   behaviour_indoors_nonhouseholders:
###     1 = Several times a day
###     2 = Every day
###     3 = 5-6 days
###     4 = 3-4 days
###     5 = 1-2 days
###     6 = Not at all
###
###   behaviour_unmasked:
###     1 = Every day
###     5-6 days
###     3-4 days
###     1-2 days
###     not at all
###
### These are recoded to ~ represent, respectively,
### 'mask wearing opportunities' and 'risk events'.

maskWearingOpportunities_recodingVector <-
  c(14/7, 1, 5.5/7, 3.5/7, 1.5/7, 0);

df[, paste0(behaviorVars_selected[1], "_recoded")] <-
  maskWearingOpportunities_recodingVector[
    df[, behaviorVars_selected[1]]
  ];

riskEvents_recodingVector <-
  c(1, 5.5/7, 3.5/7, 1.5/7, 0);

df[, paste0(behaviorVars_selected[2], "_recoded")] <-
  riskEvents_recodingVector[
    df[, behaviorVars_selected[2]]
  ];

df$behavior_composite <-
  df[, paste0(behaviorVars_selected[1], "_recoded")] *
  df[, paste0(behaviorVars_selected[2], "_recoded")];

df$behavior_composite_recoded <-
  df$behavior_composite * 5;

df$intention_behavior_composite <-
  rowMeans(
    df[,
       c('intention_composite',
         'behavior_composite_recoded')
      ],
    na.rm = TRUE);

### Invert the final measure so that higher scores represent the desirable
### behavior instead of the other way around.
df$intention_behavior_composite <-
  max(df$intention_behavior_composite, na.rm=TRUE) - 
  df$intention_behavior_composite;

###-----------------------------------------------------------------------------
### We now have two variables: a behavior composite that represents in which
### proportion of the situations where mask-wearing was the desirable behavior
### participants wore masks; and an intention-behavior composite, where this
### variable is averaged with intention.
###-----------------------------------------------------------------------------

### Use regular expressions to select variables:
###  - the | means "or";
###  - the ^ means "start of the text string"

determinantVars <- list(
  continuous =
    grep(
      
      ### We don't want intention as a determinant
      ### Also, leave out the SDT items because they're part of
      ### another study, and not easy to interpret as determinants
      ### as thet may measure two things.
      #   "^intention|^automaticity|attitude|^norms|^risk|^effective|^sdt",
      
      "^automaticity|attitude|^norms|^risk|^effective",
      
      names(df),
      value=TRUE
    ),
  dichotomous =
    grep(
      "barriers",
      names(df),
      value=TRUE
    )
);

### Superseded
#behaviorVarName <- "behaviour_unmasked";

### Using the new composite behavior measure
behaviorVarName <- "intention_behavior_composite";

#behaviorVarName_dichotomized <- "behaviour_unmasked_bool"; ### Redundant now
#
### Create dichotomized behavior measure
# df[, behaviorVarName_dichotomized] <-
#   ifelse(df[, behaviorVarName] < 5,
#          0,
#          1);

### Verify that
# table(df[, behaviorVarName],
#       df[, behaviorVarName_dichotomized]);

###-----------------------------------------------------------------------------
### Create factors for age and education
###-----------------------------------------------------------------------------

df$demographic_educationType <-
  ifelse(
    df$demographic_higher_education,
    "Theoretical",
    "Practical"
  );

df$demographic_educationType <-
  factor(
    df$demographic_educationType,
    levels = c("Practical", "Theoretical"),
    labels = c("Practical", "Theoretical"),
    ordered = TRUE
  );

ageRecodingVector <-
  c("18-29" = "Younger than 40",
    "30-39" = "Younger than 40",
    "40-49" = "40 to 59",
    "50-59" = "40 to 59",
    "60+" = "60 or older");

df$demographic_ageGroups <-
  ageRecodingVector[
    df$demographic_age
  ];

df$demographic_ageGroups <-
  factor(
    df$demographic_ageGroups,
    levels = unique(ageRecodingVector),
    labels = unique(ageRecodingVector),
    ordered=TRUE
  );

### Verify recoding

table(df$demographic_higher_education,
      df$demographic_educationType);

table(df$demographic_age,
      df$demographic_ageGroups);

###-----------------------------------------------------------------------------
### Export processed data
###-----------------------------------------------------------------------------

# write.csv(
#   df,
#   file = file.path(
#     dataPath,
#     "data--preprocessed-for-CIBER.csv"
#   )
# );

```

## Choose variables

### Matti's old version

```{r}
figure_filename_identifier <- 
  "catboost_revisedOutcome"

# unique(vartypes$type)
# 
# target <- c("behaviour_unmasked", 
#             # "intention_indoor_meeting"
#             "behaviour_indoors_nonhouseholders")

types_included <- c(
  # "demographic",
  # "behaviour",
  # "mask_wearing",
  # "intention",
  "automaticity",
  # "post_covid_maskwearing",
  "instrumental_attitude",
  "norms",
  "affective_attitude",
  # "barriers",
  "effective_means",
  "perceived_risk"
  # "sdt_needs",
  # "sdt_motivation"
  # "attention_check",
  # "vaccination_status",
  # "needprotection"
  # "children_age_groups"
  )


df_eng_ml <- df %>% 
  dplyr::select(id,
                sampling_weight,
                intention_behavior_composite,
                demographic_ageGroups,
                demographic_educationType,
                all_of(determinantVars$continuous))

df_eng_ml_analysis <- df_eng_ml 

# df_eng_ml_analysis$target %>% table()
```

## Vartypes prep

### Wrangle ordered and unordered factors

Create dataframe with the appropriate measurement scales (from: <https://docs.google.com/spreadsheets/d/1BEX4W8XRGnuDk4Asa_pdKij3EIZBvhSPqHxFrDjM07k/edit#gid=935884211>)

```{r}
 
df_eng_ml_analysis_ordered <- df_eng_ml_analysis %>% 
  # # EVERYTHING but name and weights AS FACTORS
  dplyr::mutate(across(.cols = -c(id, sampling_weight, 
                                  intention_behavior_composite,
                                  demographic_ageGroups,
                                  demographic_educationType),
                        ~factor(., ordered = TRUE))) %>%
  dplyr::rename(target = intention_behavior_composite,
                demographic_age = demographic_ageGroups,
                demographic_education = demographic_educationType) %>% 
  dplyr::mutate(target = dplyr::case_when(
    target >= 9.25 ~ "Optimal",
    target > 9 & target < 9.25 ~ as.character(NA),
    target <= 9 ~ "Improvable"),
    target = factor(target)) %>%
  na.omit()

 # df_eng_ml_analysis %>% ggplot(aes(x = intention_behavior_composite)) +
 #   geom_histogram(binwidth = 0.01) +
 #   scale_x_continuous(breaks = seq(from = 0, to = 10, by = 1))
 # 
 # df_eng_ml_analysis_ordered$target %>% table
```

# Descriptives

```{r}
# purrr::map(df_eng_ml_analysis_ordered %>% 
#              dplyr::select(-id, -sampling_weight),
#            .f = ~table(.x))

# purrr::map_dfr(.x = df_eng_ml_analysis, .f = ~sum(is.na(.x))) %>% 
#   tidyr::pivot_longer(cols = everything(),
#                       names_to = "variable",
#                       values_to = "missing") %>% 
#   dplyr::filter(missing != 0) %>% 
#   dplyr::arrange(desc(missing))

# purrr::map(.x = df_eng_ml_analysis_ordered_filtered %>% 
#              dplyr::select(-demographic_id, 
#                            -weighting,
#                            -demographic_county), .f = ftable)

```


# Random forests

## Create model

```{r}
importance_metric <- "shap"

targetVariable <- "target"
omittedVariables <- c("")
    
rf_group <- list(c("Younger than 40", "40 to 59", "60 or older"),
                 c("60 or older"),
                 c("40 to 59"),
                 c("Younger than 40")
                 )

df_fulldata <- list()
df_fulldata_noid <- list()
df_train_noid_balanced <- list()
target_data <- list()
training_data_balanced_notarget <- list()
df_train_noid <- list()
df_test_noid <- list()
test_weights <- list()

df_train_orig <- list()
df_test_orig <- list()
training_weights <- list()
  
target_balance_in_train <- list()
target_balance_in_test <- list()
target_balance_in_train_after_overunder_sampling <- list()

hyper_grid <- list()
model_ordinalForest <- list()

model_catboost_optimal <- list()

start_time <- Sys.time()

all_cores <- parallel::detectCores(logical = FALSE)
cl <- parallel::makePSOCKcluster(all_cores)
doParallel::registerDoParallel(cl)

for (i in 1:length(rf_group)){
  
df_fulldata[[i]] <- df_eng_ml_analysis_ordered %>% 
  dplyr::filter(demographic_age %in% rf_group[[i]])

set.seed(100)

df_train_orig[[i]] <- df_fulldata[[i]] %>% 
  # This stratifies the sample so that the grouping vars are comparably present 
  dplyr::group_by(target, demographic_age) %>% 
  dplyr::slice_sample(prop = 0.70) %>% 
  dplyr::ungroup()

df_test_orig[[i]] <- dplyr::anti_join(df_fulldata[[i]],
                            df_train_orig[[i]],
                            by = "id")

training_weights[[i]] <- df_train_orig[[i]]$sampling_weight
test_weights[[i]] <- df_test_orig[[i]]$sampling_weight

df_fulldata_noid[[i]] <- df_fulldata[[i]] %>%
  dplyr::select(-`id`, -sampling_weight, -demographic_age)
df_train_noid[[i]] <- df_train_orig[[i]] %>% 
  dplyr::select(-`id`, -sampling_weight, -demographic_age)
df_test_noid[[i]] <- df_test_orig[[i]] %>% 
  dplyr::select(-`id`, -sampling_weight, -demographic_age)

# cat("Target variable in TRAIN:")
target_balance_in_train[[i]] <- df_train_noid[[i]]$target %>% table
# cat("Target variable in TEST:")
target_balance_in_test[[i]] <- df_test_noid[[i]]$target %>% table

# # Under- and oversampling to balance data
df_train_noid_balanced[[i]] <- #df_train_noid[[i]]
  ROSE::ovun.sample(formula = target ~ .,
                    data = df_train_noid[[i]],
                    p = 0.5,
                    seed = 1,
                    method = "both")$data

# cat("Target variable in TRAIN -- after overunder_sampling:")
target_balance_in_train_after_overunder_sampling[[i]] <-  
  df_train_noid_balanced[[i]]$target %>% table

predicted_class <- "Adequate_masking"

# hyperparameter grid search: define grid
hyper_grid[[i]] <- expand.grid(depth = c(4, 6, 8),
                    learning_rate = 0.1,
                    iterations = 50, #500
                    l2_leaf_reg = 1e-3,
                    rsm = 0.95,
                    border_count = 64)

## total number of combinations:
# nrow(hyper_grid)

# specify that the resampling method is 
traincontrol_parameters <- caret::trainControl(
  method = "repeatedcv",
  search = "grid",
  number = 10,
  repeats = 10,
  timingSamps = 5)

set.seed(2021)
model_catboost_optimal[[i]]  <- 
  caret::train(x = df_train_noid_balanced[[i]] %>% 
                 dplyr::select(-target),
               y = df_train_noid_balanced[[i]] %>% 
                 dplyr::select(target) %>% 
                 dplyr::pull(),
               # cat_features = c(0:length(df_train_noid_balanced[[i]])-1),
               weights = training_weights[[i]],
               method = catboost.caret,
               logging_level = 'Silent',
               trControl = traincontrol_parameters,
               preProc = NULL
  )

}

end_time <- Sys.time()
end_time - start_time

parallel::stopCluster(cl)

foreach::registerDoSEQ()

```

## Check correlations

```{r}

df_test_noid[[1]] %>%
  purrr::map(.x = ., .f = ~as.numeric(levels(.))[.]) %>% 
  dplyr::bind_cols() %>% 
  dplyr::select(-target) %>% 
  cor(use = "pairwise.complete.obs",
      method = "spearman") %>% 
  tibble::as.tibble() %>% 
  dplyr::mutate(var1 = names(.)) %>% 
  tidyr::pivot_longer(-var1,
                      names_to = "var2",
                      values_to = "correlation") %>% 
  dplyr::filter(correlation != 1) %>%
  dplyr::filter(abs(correlation) >= 0.612) %>% 
  # rowwise() %>% 
  # dplyr::mutate(varpair = sort(paste0("var1"), paste0("var2"), decreasing = FALSE))
  dplyr::arrange(desc(correlation)) %>% 
  dplyr::group_by(correlation) %>% 
  dplyr::slice(-1) %>% 
  dplyr::ungroup() %>% 
  ggplot(aes(x = correlation)) +
  geom_density() +
  theme_bw()

  

```


## Predict with model

```{r}
predicted_class <- "Improvable"
  
results_ <- list()
auc <- list()
confusion_matrix <- list()
rocCurve <- list()

for(i in 1:length(rf_group)) {
  # Predict on the testing data 
  set.seed(2021)
  results_[[i]] <- 
    df_test_noid[[i]] %>%
    select(target) %>%
    as_tibble()%>%
    mutate(
      model_class = predict(model_catboost_optimal[[i]],
                            df_test_noid[[i]]),
      model_prob  = predict(model_catboost_optimal[[i]], 
                            df_test_noid[[i]], type = "prob")[, predicted_class])

# Compute the AUC  
  auc[[i]] <- results_[[i]] %>% 
    dplyr::mutate(target = factor(target)) %>% 
    yardstick::roc_auc(truth = target, model_prob)
# Compute the confusion matrix
  confusion_matrix[[i]] <- caret::confusionMatrix(
    data = predict(model_catboost_optimal[[i]],
                   df_test_noid[[i]] %>% 
    dplyr::mutate(target = factor(target))),
    reference = factor(df_test_noid[[i]]$target))
  
  # Plot the ROC curve
  rocCurve[[i]] <- yardstick::roc_curve(results_[[i]]  %>% 
                                          dplyr::mutate(target = factor(target)), 
                                        truth = target, 
                                        model_prob) %>%
    ggplot(aes(x = 1 - specificity, 
               y = sensitivity)) +
    geom_path(colour = "darkgreen", size = 1.5) +
    geom_abline(lty = 3, size= 1, colour = "darkred") +
    coord_equal()+
    theme_light()

rocCurve[[i]]

cat("Confusion matrix for the tuned model:\n")  
  print(confusion_matrix[[i]]) # For tuned model
  
}

purrr::map2(.x = auc,
            .y = rf_group,
            .f = ~paste("Age groups:", 
                        paste(.y, collapse = ", "),
                        "| AUC for the tuned model:", 
                        .x %>% dplyr::pull(.estimate) %>% 
                          round(., digits = 4)))
```

### Extract SHAP values

```{r}

train_pool <- purrr::map(
  .x = df_train_noid_balanced,
  .f = ~catboost.load_pool(
    data = .x %>%
      dplyr::select(-target),
    label = .x %>%
      dplyr::select(target) %>%
      dplyr::mutate(target = case_when(target == "Improvable" ~ 0,
                                       TRUE ~ 1)) %>%
      dplyr::pull() %>%
      as.numeric()))
                         
full_data_pool <- purrr::map(
  .x = df_fulldata_noid,
  .f = ~catboost.load_pool(
    data = .x %>% 
      dplyr::select(-target),
    label = .x %>%
      dplyr::select(target) %>%
      dplyr::mutate(target = case_when(target == "Improvable" ~ 0,
                                       TRUE ~ 1)) %>%
      dplyr::pull() %>%
      as.numeric()))

# catboost_train_object <- catboost.train(
#   train_pool[[i]],  
#   NULL,
#   params = list(loss_function = 'Logloss',
#                 iterations = 100, metric_period=10)
#   )

# catboost_prediction <- catboost.predict(catboost_train_object, 
#                                         test_data_pool[[i]])

shap_values <- purrr::map2(.x = model_catboost_optimal,
                           .y = full_data_pool,
                           .f = ~catboost.get_feature_importance(
                             .x$finalModel,
                             pool = .y,
                             type = "ShapValues") %>% 
                             tibble::as_tibble(.name_repair = "unique") %>% 
                             dplyr::select(-last_col()))

# purrr::map(.x = shap_values, .f = ~as.data.frame(.x))
```

## Plotting

### Plot SHAP values

#### Individual plots for convexity analysis

```{r}
varnames_for_shap <- df_fulldata_noid[[4]] %>% 
  dplyr::select(-target) %>%
  names()

shap_viz_df <- purrr::pmap(
  list(..1 = shap_values,
       ..2 = df_fulldata_noid),
  .f = ~dplyr::full_join(y = ..1 %>% 
                           dplyr::rename_all(~varnames_for_shap) %>% 
                           dplyr::mutate(id = dplyr::row_number(), 
                                         type = "shap") %>% 
                           dplyr::mutate(across(everything(), as.character)) %>% 
                           tidyr::pivot_longer(cols = -c(type, id)),
                         x = ..2 %>% 
                           dplyr::select(-target) %>% 
                           dplyr::mutate(id = dplyr::row_number(),
                                         type = "response") %>% 
                           dplyr::mutate(across(everything(), as.character)) %>%
                           tidyr::pivot_longer(cols = -c(type, id)),
                         by = c("id", "name"),
                         suffix = c("_response", "_shap")))

# for(k in 1)
# for(i in varnames_for_shap) {
# print(shap_viz_df[[k]] %>% 
#     dplyr::filter(name == i) %>% 
#   ggplot(aes(x = value_response,
#              y = value_shap,
#              fill = value_shap)) +
#     geom_hline(yintercept = 0, colour = "red", linetype = "dashed") +
#         geom_violin() +
#     # geom_point(size = 0.1, alpha = 0.6) +
#     geom_boxplot(width = 0.05, outlier.shape = NA) +
#     # geom_line(aes(group = value_response)) +
#     labs(x = paste0(i)) +
#     labs(y = NULL, 
#          title = paste0("Contributions to model prediction"),
#          caption = paste0("Age group(s): ",               
#                           paste(rf_group[[i]], collapse = ", "),
#                           collapse = "")) +
#     theme_bw())
# }

pdf(paste0("images/matti_", 
           figure_filename_identifier,
           "_shaps.pdf"), 
           onefile = TRUE)

for(i in 1:length(rf_group)){
  print(shap_viz_df[[i]] %>%  
          dplyr::group_by(name) %>% 
          dplyr::mutate(shap_variance = var(value_shap, na.rm = TRUE)) %>% 
          dplyr::ungroup() %>% 
          dplyr::mutate(name = factor(name, ordered = TRUE),
                        name = forcats::fct_reorder(name, shap_variance),
                        value_shap = as.numeric(value_shap)) %>% 
          dplyr::filter(name != "demographic_education") %>% 
  ggplot(aes(x = value_shap,
             y = name,
             colour = value_response)) +
    geom_point(aes(alpha = 1), position = "jitter", size = 0.1) +
    geom_vline(xintercept = 0, colour = "black", linetype = "solid") +
    scale_colour_viridis_d(end = 0.8, option = "inferno") +
    labs(y = NULL, 
         title = paste0("Contributions to model prediction"),
         caption = paste0("Age group(s): ",               
                 paste(rf_group[[i]], collapse = ", "),
                                 collapse = "")) +
    guides(alpha = "none") + 
    theme_bw())
}
dev.off()

#### n per response value in each group
# purrr::map(.x = shap_viz_df,
#            .f = ~.x %>% 
#              tidyr::pivot_wider(names_from = name, 
#                                 values_from = value_response) %>% 
#              dplyr::select(-id, -type_response, -type_shap, -value_shap) %>% 
#              purrr::map(.f = ~table(.x)))

```

### Performance summary

```{r}
# Renaming columns to reflect groups
new_varnames <- purrr::map(.x = rf_group,
                           .f = ~paste(.x, collapse = ", "))

new_varnames[[1]] <- "All ages"

performance_table <- purrr::map(.x = confusion_matrix,
           .f = ~.x %>%
             broom::tidy() %>% 
             dplyr::select(term, estimate) %>% 
             dplyr::filter(term == "balanced_accuracy" |
                             term == "accuracy" |
                             term == "kappa")) %>% 
  dplyr::bind_rows() %>% 
  dplyr::mutate(group = rep(unlist(new_varnames), each = 3)) %>% 
  tidyr::pivot_wider(names_from = term,
                     values_from = estimate) %>% 
  dplyr::mutate(AUC = bind_rows(auc)$.estimate)

performance_plot <- purrr::map(.x = confusion_matrix,
           .f = ~.x %>%
             broom::tidy() %>% 
             dplyr::select(term, estimate) %>% 
             dplyr::filter(term == "balanced_accuracy" |
                             term == "accuracy" |
                             term == "kappa")) %>% 
  dplyr::bind_rows() %>% 
  dplyr::mutate(group = rep(unlist(new_varnames), each = 3),
                group = forcats::fct_relevel(group, 
                                             "Younger than 40",
                                             "40 to 59",
                                             "60 or older",
                                             "All ages")) %>% 
  tidyr::pivot_wider(names_from = term,
                     values_from = estimate) %>% 
  dplyr::mutate(AUC = bind_rows(auc)$.estimate) %>% 
  # dplyr::rename(`1-kappa` = kappa) %>% 
  tidyr::pivot_longer(-group) %>% 
  ggplot(aes(x = group,
             y = value, 
             colour = name)) +
  geom_point(size = 4) + 
  geom_segment(aes(x = group, 
                   xend = group,
                   y = 0,
                   yend = value)) +
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(breaks = seq(from = 0, to = 1, by = 0.1)) +
  labs(x = NULL, y = NULL) +
  theme_bw() +
  theme(legend.position = "none",
        panel.grid.minor = element_blank()) +
  facet_wrap(~name)

performance_plot

ggsave(paste0("images/matti_performance_", 
              figure_filename_identifier, 
              ".png"))

performance_table

```



### Plot "normal" values

... whatever they mean here, I don't know. These may have to go. 

```{r}
varimp_data <- purrr::map(.x = model_catboost_optimal,
                          .f = ~caret::varImp(.x, scale = FALSE)$importance %>% 
                            tibble::as_tibble(rownames = NA) %>% 
                            rownames_to_column(var = "Variable"))

# varimp_data_viz <- purrr::map(.x = varimp_data,
#                               .f = ~.x %>% 
#                                 tibble::rownames_to_column(var = "Variable")) 
                             
varimp_data_viz_ordered <- 
  purrr::map(.x = varimp_data,
             .f = ~.x %>% 
               dplyr::mutate(Variable = 
                               forcats::fct_reorder(Variable, Overall)))
             
# Use to match a subset's variable order to that of the whole group 
order_to_match <- varimp_data_viz_ordered[[1]]$Variable

varimp_plots_groups <- purrr::pmap(list(..1 = varimp_data_viz_ordered,
                                        ..2 = rf_group,
                                        ..3 = auc),
            .f = ~..1 %>% 
              # # Matching order with that of the whole group is messy; omit.
              # dplyr::mutate(Variable = factor(Variable, 
              #                                 levels = rev(order_to_match))) %>% 
              ggplot(aes(y = Variable,
                         x = Overall,
                         fill = Overall)) +
              geom_bar(stat = "identity", position = "dodge") +
              labs(x = "Importance",
                   title = paste("Age groups:", 
                                 paste(..2, collapse = ", "),
                                 collapse = ""),
                   caption = paste("AUC:", ..3 %>% dplyr::pull(.estimate) %>% 
                         round(., digits = 3))) +
              
              theme_bw() +
              guides(fill = "none") +
              scale_fill_viridis_c(option = "inferno",
                                   end = 0.8))


for (i in 1:length(varimp_plots_groups)) {
  ggsave(filename = paste0("rf/varimp_rf_", 
                           paste(rf_group[[i]], collapse = "_"),
                           figure_filename_identifier,
                           ".png"), 
         plot = varimp_plots_groups[[i]],
         width = 14, 
         height = 14)
}

# tibble::as_tibble(ordinalForest::importance(model_catboost_optimal),
#                   rownames = "variable") %>%
#   dplyr::mutate(variable = forcats::fct_reorder(variable, `value`)) %>%
#   # tidyr::pivot_longer(cols = -variable) %>%
#   ggplot(aes(x = variable,
#              y = value,
#              fill = value)) +
#   geom_bar(stat = "identity", position = "dodge") +
#   coord_flip() +
#   labs(y = paste("Variable importance:", importance_metric),
#        x = NULL,
#        title = NULL,
#        caption = paste("AUC:", auc %>% dplyr::pull(.estimate) %>%
#                          round(., digits = 3))) +
#   theme_bw() +
#   guides(fill = "none") +
#   scale_fill_viridis_c(option = "inferno",
#                        end = 0.8)
# 
# ggsave(".png",
#        width = 14, height = 14)
# 
# tibble::as_tibble(ordinalForest::importance(model_catboost_optimal),
#                                    rownames = "variable") %>% 
#   dplyr::left_join(vartypes %>% dplyr::rename(variable = name), 
#                    by = "variable") %>% 
#   dplyr::mutate(variable = forcats::fct_reorder(variable, `value`)) %>% 
#   ggplot(aes(x = variable,
#              y = value,
#              fill = value)) +
#   geom_bar(stat = "identity", position = "dodge") + 
#   coord_flip() +
#   labs(y = paste("Variable importance:", importance_metric),
#        x = NULL,
#        title = NULL,
#        caption = paste("AUC:", auc %>% dplyr::pull(.estimate) %>% 
#                          round(., digits = 3))) +
#   theme_bw() +
#   guides(fill = "none") +
#   scale_fill_viridis_c(option = "inferno",
#                        end = 0.8) +
#   facet_grid(type ~ ., scales = "free", space = "free") 
#  
# ggsave("taloustutkimus_RF_ordinalForest_respect.unordered.factors_true.png",
#        width = 14, height = 14)
```

### Differences in variable importance compared to full data

```{r}
# Renaming columns to reflect groups
new_varnames <- purrr::map(.x = rf_group,
                           .f = ~paste(.x, collapse = ", "))

new_varnames[[1]] <- "All ages"

varimp_renamed <- purrr::map2(.x = varimp_data_viz_ordered,
           .y = new_varnames,
           .f = ~.x %>% 
             # https://stackoverflow.com/a/46616742
             dplyr::rename(!!.y := Overall))

# Merge the data frames with different age groups
varimp_renamed_joined <- varimp_renamed %>% 
  purrr::reduce(left_join, by = "Variable")

percentile_dropped <- 20

varimp_renamed_joined_dropped <- varimp_renamed_joined %>% 
  dplyr::mutate(importance_sum = rowSums(across(where(is.numeric)))) %>% 
  # Drop the values that are not important in any of the groups
  filter(`All ages` > quantile(importance_sum, percentile_dropped/100)) 

# Calculate differences from importances in full dataset
varimp_renamed_joined_diff <- varimp_renamed_joined_dropped %>% 
  dplyr::rowwise() %>% 
  dplyr::mutate(across(-c("Variable", `All ages`, importance_sum),
                ~., #- `All ages`,
                .names = "{.col}_diff")) %>% 
  dplyr::ungroup()

varimp_diff_viz <- varimp_renamed_joined_diff %>% 
  dplyr::mutate(ordering = `All ages`) %>%
  tidyr::pivot_longer(c(`All ages`, contains("_diff")),
                      names_to = "Group",
                      values_to = "importance_diff") %>% 
  # dplyr::mutate(Variable = paste0(Variable, 
  #                                 " (", 
  #                                 round(`All ages`, digits = 0),
  #                                 ")")) %>% 
  # # For plotting, order the variables according to...
  # dplyr::group_by(Variable) %>% 
  # dplyr::mutate(ordering = sum(abs(importance_diff))) %>% 
  # dplyr::ungroup() %>%
  # Reorder by previously defined rule
  dplyr::mutate(Variable = forcats::fct_reorder(Variable, abs(ordering))) %>% 
  dplyr::mutate(Group = stringr::str_remove(string = Group,
                                            pattern = "_diff")) %>% 
  dplyr::select(Variable, Group, importance_diff) 

# head(varimp_diff_viz)

varimp_diff_viz_with_aggregate_importance <- dplyr::left_join(
  x = varimp_diff_viz,
  y = varimp_renamed_joined %>% 
    dplyr::select(Variable, aggregate_importance = `All ages`),
  by = "Variable")

```

#### Make plots

```{r}
plot_varimp_subgroup_diffs <- varimp_diff_viz_with_aggregate_importance %>%
  dplyr::filter(stringr::str_detect(string = Variable,
                                    pattern = "demographic_age",
                                    negate = TRUE)) %>%
  dplyr::filter(Group != "All ages") %>% 
  ggplot(aes(y = Variable,
             x = importance_diff,
             fill = importance_diff)) +
  geom_bar(stat = "identity", position = "dodge") +
  # # Point indicating aggregate importance; not very clear 
  # geom_point(aes(x = 0,
  #                y = Variable,
  #                fill = aggregate_importance,
  #                size = aggregate_importance,
  #                alpha = 0.5)) +
  labs(x = "Difference in importance",
       y = NULL) +
  theme_bw() +
  guides(fill = "none",
         size = "none",
         alpha = "none") +
  scale_fill_viridis_c(option = "inferno",
                       end = 0.8) +
  theme(text = element_text(size = 20)) +
  facet_wrap(~Group, 
             #ncol = 3
             )

plot_varimp_aggregate_absolutes <- varimp_diff_viz_with_aggregate_importance %>%
  dplyr::filter(stringr::str_detect(string = Variable,
                                    pattern = "demographic_age",
                                    negate = TRUE)) %>%
  dplyr::filter(Group == "All ages") %>% 
  ggplot(aes(y = Variable,
             x = importance_diff,
             fill = importance_diff)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Absolute importance",
       y = NULL,
       caption = paste0(
  "- Zero values indicate importance is equal to that of full group.\n",
  "- Positive (negative) values indicate variable is ",
  "more (less) important in subgroup.\n",
  # "- Size of ball represents importance",
  # "in the model with full population.\n",
  "- ", percentile_dropped,
  " percent of variables with smallest importance values omitted.\n"
  # "- Variables are ordered by ",
  # "sum of absolute values of differences from population value."
  )
       ) +
  theme_bw() +
  guides(fill = "none",
         size = "none",
         alpha = "none") +
  scale_fill_viridis_c(option = "inferno",
                       end = 0.8) +
  theme(text = element_text(size = 20)) +
  facet_wrap(~Group, 
             #ncol = 3
             )

cowplot::plot_grid(plot_varimp_subgroup_diffs, 
                   plot_varimp_aggregate_absolutes +
                     theme(axis.text.y = element_blank(),
                           axis.line.y = element_blank(),
                           axis.title.y= element_blank(),
                           axis.ticks.y= element_blank()),
                   nrow = 1,
                   rel_widths = c(3, 1),
                   align = 'h', axis = 'tb')

ggsave(filename = paste0("rf/", figure_filename_identifier, ".png"), 
       width = 14, 
       height = 14)

```





### Inspect classified individuals

```{r}
# data_with_predictions <- data.frame(prediction = 
#                                       predict(model_catboost_optimal,
#                                               data = df_fulldata)$predictions,
#                                     df_fulldata)
# 
# for(i in levels(df_eng_ml_analysis$demographic_age)){
#   
# data_for_plot <- df_eng_ml_analysis %>% 
#     dplyr::mutate_all(as_factor) %>% 
#     dplyr::filter(demographic_age == i) %>%
#     dplyr::mutate_all(as_factor) #%>% 
#   # dplyr::filter(prediction == target)
# 
# n_observations <- nrow(data_for_plot)
#   print(
#     data_for_plot %>% 
#       ggplot(aes(fill = target, 
#                  x = demographic_region)) +
#       labs(y = NULL,
#            title = paste0("Age group ", i, ", n = ", n_observations),
#            # x = "Agreement with being vaccinated or intending to get the shots"
#            ) +
#       geom_bar(position = "fill") +
#       scale_fill_viridis_d() +
#       theme_bw() +
#       theme(axis.text.x = element_text(angle = 20, hjust = 1),
#             legend.title = element_blank())
#     )
# }  
```

# Trash

```{r}

### GRID SEARCH WITHOUT CARET
# for(k in 1:nrow(hyper_grid[[i]])) {
#   
#   # train model
#   model_ordinalForest[[i]] <- ordinalForest::ordinalForest(
#     formula = target ~ .,
#     data = df_train_noid_balanced[[i]],
#     importance = importance_metric,
#     case.weights = training_weights[[i]],
#     respect.unordered.factors = TRUE,
#     num.trees       = hyper_grid[[i]]$num_trees[k],
#     mtry            = hyper_grid[[i]]$mtry[k],
#     min.node.size   = hyper_grid[[i]]$node_size[k],
#     sample.fraction = hyper_grid[[i]]$sample_size[k],
#     seed            = 123
#   )
#   
#   # add OOB error to grid
#   hyper_grid[[i]]$OOB_RMSE[k] <- sqrt(model_ordinalForest[[i]]$prediction.error)
# }


#### GROUPED K-FOLD CROSS-VALIDATION; DOESN'T WORK WITH SAMPLING WEIGHTS
# ## "Fix" function caret::groupKFold() to produce the requested number of folds
# ## https://github.com/topepo/caret/issues/1150#issuecomment-692607981
# groupKFold_wrangled <- function(group, k = length(unique(group))) {
#   g_unique <- unique(group) 
#   m <- length(g_unique)
#   if (k > m) {
#     stop("`k` should be less than ", m)
#   }
#   pre_group <- rep(1:k, each=m/k)
#   g_folds <- sample(pre_group, size = m, replace = FALSE)
#   
#   out <- split(seq_along(group), g_folds[match(group, g_unique)])
#   names(out) <- paste0("Fold", gsub(" ", "0", 
#                                     format(seq_along(out))))
#   lapply(out, function(z) seq_along(group)[-z])
# }
# 
# 
# grouping <- df_train_noid_balanced[[i]]$demographic_8_areas
# 
# ## This creates k subsets of the data, each of which contains unbroken groups,
# ## with one group left unchosen for the fold
# group_folds <- groupKFold_wrangled(
#   df_train_noid_balanced[[i]]$demographic_8_areas, 
#   k = 8)
# 
# # specify that the resampling method is 
# group_fit_control <- caret::trainControl(## use grouped CV folds
#   index = group_folds,
#   method = "cv")

# ##### OPTIMAL MODEL WITHOUT CARET
# optimal_params <- hyper_grid[[i]] %>% 
#   dplyr::arrange(OOB_RMSE) %>% 
#   dplyr::slice(1)
# 
#   model_catboost_optimal[[i]] <- ordinalForest::ordinalForest(
#     formula = target ~ .,
#     data = df_train_noid[[i]],
#     importance = importance_metric,
#     case.weights = training_weights[[i]],
#     respect.unordered.factors = TRUE,
#     num.trees       = optimal_params$num_trees,
#     mtry            = optimal_params$mtry,
#     min.node.size   = optimal_params$node_size,
#     sample.fraction = optimal_params$sample_size,
#     seed            = 123
#   )
#   
#   model_catboost_optimal_prob[[i]] <- ordinalForest::ordinalForest(
#     formula = target ~ .,
#     data = df_train_noid[[i]],
#     importance = importance_metric,
#     case.weights = training_weights[[i]],
#     respect.unordered.factors = TRUE,
#     num.trees       = optimal_params$num_trees,
#     mtry            = optimal_params$mtry,
#     min.node.size   = optimal_params$node_size,
#     sample.fraction = optimal_params$sample_size,
#     seed            = 123,
#     probability = TRUE
#   )

```

