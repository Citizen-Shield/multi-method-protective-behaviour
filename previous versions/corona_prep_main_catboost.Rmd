---
title: "Corona prepping using Finnish data Decision Trees"
author: "James Twose"
output: html_notebook
---

Main question: at this point we're interested in one single classification, i.e. what predicts whether people do maskless contacts with non-householders

[Research Document](https://docs.google.com/document/d/1iLciHcvVvf8QwFS7wiyNBevpD1B9yDRqMlM4_oCcVcA/edit?usp=sharing)

[Questions codebook](https://docs.google.com/document/d/1YZVCP1UNxnNLAK2kYDfA9Y98leTZYurZD-d8iByhdi0/edit?usp=sharing)

[Method of delivery](https://docs.google.com/document/d/1G1JT9JUJrTK3aaXXuRawYACJaGNxU7mcXL9i-d8eKXY/edit)

```{r, echo=FALSE, message=FALSE}
library(ggplot2)
library(parsnip)
library(magrittr)
library(dplyr)
library(faux)
library(DataExplorer)
library(caret)
library(randomForest)
library(tidyr)
library(cvms)
library(doParallel)
library(rattle)
library(rpart)
source("coronapreppers_extras.R")
# devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.26/catboost-R-Darwin-0.26.tgz')
library(catboost)

# instal shapper
# devtools::install_github("ModelOriented/shapper")

# install shap python library
# shapper::install_shap()

```

```{r}
sessionInfo()
```


```{r}
df <- read.csv("data/shield_gjames_21-06-10.csv")
```

```{r}
grouping_var <- "behaviour_unmasked"
# feature_list <- colnames(df[, !(names(df) %in% c(grouping_var, "id"))])
# feature_list <- c('intention_indoor_meeting', 'norms_people_present_indoors',
#        'sdt_motivation_extrinsic_2', 'sdt_motivation_identified_4', 'norms_family_friends', 'norms_risk_groups', 'norms_officials',
#        'norms_people_present_indoors')
```

```{r}
if (grouping_var == "behaviour_unmasked") {
  # df <- df %>% mutate(tmp = if_else(!!as.symbol(grouping_var) != 5, 'bad', 'good'))
  df <- df %>% mutate(tmp = if_else(!!as.symbol(grouping_var) != 5, 0, 1))

  names(df)[names(df) == 'tmp'] <- paste0(grouping_var, "_bool")
}
    
```

```{r}
df[, paste0(grouping_var, "_bool")] <- as.factor(df[, paste0(grouping_var, "_bool")])
```

```{r}
# df %<>%
#        mutate_each_(funs(factor(.)), colnames(df))
# str(df)

ordinal_vars_mydata <- ordering_lookup %>% 
  dplyr::filter(varname %in% names(df)) %>% 
  dplyr::filter(ordering == "ordered")
  
df <- df %>% 
  # Ordered variables as ordinal factors
  dplyr::mutate(across(.cols = ordinal_vars_mydata$varname, 
                        ~factor(., ordered = TRUE))) %>% 
  # Everything else as unordered factors
  dplyr::mutate(across(.cols = -ordinal_vars_mydata$varname, 
                        ~factor(.))) %>% 
  # Fix ordering in the intention variables
  dplyr::mutate(across(.cols = contains("intention_"), 
                        ~dplyr::recode_factor(.,
                                              "1" = "4",
                                              "2" = "1", 
                                              "3" = "2",
                                              "4" = "3",
                                              .ordered = TRUE)))

str(df)

```

```{r, fig.height=15, fig.width=15}
# Exploratory data analysis
plot_intro(df)
plot_bar(df)
plot_correlation(df)
```


```{r}
head(df[, c(paste0(grouping_var, "_bool"), grouping_var)])
```

```{r}
x <- df %>%
  select(-behaviour_unmasked_bool, -behaviour_unmasked, -id) %>%
  as.data.frame()

y <- df$behaviour_unmasked_bool
```


```{r}
set.seed(2021)
inTrain <- createDataPartition(y, p = .80, list = FALSE)[,1]

x_train <- x[ inTrain, ]
x_test  <- x[-inTrain, ]

y_train <- y[ inTrain]
y_test  <- y[-inTrain]

colnames(x_train)
```


```{r}
fit_control <- trainControl(method = "repeatedcv",
                            number = 10, #10
                        repeats=10, #10
                            classProbs = TRUE)
```


```{r}
grid <- expand.grid(depth = c(4, 6, 8),
                    learning_rate = 0.1,
                    iterations = 50, #500
                    l2_leaf_reg = 1e-3,
                    rsm = 0.95,
                    border_count = 64)
```


```{r}
tictoc::tic()
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

set.seed(69420)

report <- train(x, as.factor(make.names(y)),
                method = catboost.caret,
                logging_level = 'Silent', #'Verbose', 
                preProc = NULL,
                tuneGrid = grid, trControl = fit_control)

stopCluster(cl)
tictoc::toc()
```

```{r}
registerDoSEQ()
```

```{r}
report
```

```{r}
report$results
```


```{r}
importance <- varImp(report, scale = FALSE)
importance
```

```{r}
x_pool <- catboost.load_pool(x)

model <- report$finalModel
model
```

```{r}
shap_values <- catboost.get_feature_importance(
  model,
  pool = x_pool,
  type = "ShapValues",
  thread_count = -1,
  fstr_type = NULL
)
```


```{r}
shap_values_df <- data.frame(shap_values[, 1:ncol(x)])
colnames(shap_values_df) <- colnames(x)

shap_values_df_melt <- reshape2::melt(shap_values_df, value.name="shap_value")

tmp_x <- data.frame(sapply(x, as.numeric))

actual_values_df_melt <- reshape2::melt(tmp_x, value.name="actual_value")

shap_actual_df <- cbind(actual_values_df_melt, shap_values_df_melt["shap_value"])
```

```{r}
# shap_actual_df[c("actual_value", "shap_value")] <- sapply(shap_actual_df[c("actual_value", "shap_value")], as.factor)

shap_actual_df[c("actual_value")] <- sapply(shap_actual_df[c("actual_value")], as.factor)
```


```{r, fig.height=15}
ggplot(shap_actual_df, aes(x=shap_value, y=variable, color=actual_value)) + 
  geom_jitter()
```


```{r}
stop!
```



```{r}
# Post prediction
postResample(predict(dec_mod, x_test), y_test)
```


```{r}
prediction_tibble <- tibble("target"=y_test,
       "prediction"=predict(dec_mod, x_test))
prediction_table <- table(prediction_tibble)
cfm <- as_tibble(prediction_table)
plot_confusion_matrix(cfm, 
                      target_col = "target", 
                      prediction_col = "prediction",
                      counts_col = "n")
```

```{r, fig.height=10, fig.width=15}
fancyRpartPlot(dec_mod$finalModel)
```


```{r}
pred_df <- data.frame(target=as.numeric(y_test),
           prediction=as.numeric(predict(dec_mod, x_test)),
           row.names = rownames(x_test))

pred_df$correct_or_not <- pred_df$target + pred_df$prediction

zero_ids <- rownames(pred_df[pred_df[, "correct_or_not"] == 2,])
one_ids <- rownames(pred_df[pred_df[, "correct_or_not"] == 4,])

length(zero_ids)
length(one_ids)
```

```{r}
df[zero_ids, ]
df[one_ids, ]
```

```{r}
top_features <- rownames(head(varimp_data$importance, 3))
# top_features <- c("behaviour_indoors_nonhouseholders", "behaviour_close_contact", "intention_indoor_meeting")
```

```{r}
# df$demographic_gender <- factor(df$demographic_gender)
# df <- data.frame(apply(df, 2, factor))
```

```{r}
# df %<>%
#        mutate_each_(funs(factor(.)),top_features)
# # str(df)
```


```{r}
x <- df[top_features]

y <- factor(df$behaviour_unmasked_bool)

```

```{r}
set.seed(2021)
inTrain <- createDataPartition(y, p = .80, list = FALSE)[,1]

x_train <- x[ inTrain, ]
x_test  <- x[-inTrain, ]

y_train <- y[ inTrain]
y_test  <- y[-inTrain]

colnames(x_train)
```

```{r}
cl <- makePSOCKcluster(10)
registerDoParallel(cl)

set.seed(2021)

# Specify 10 fold cross-validation
ctrl_cv <- trainControl(method = "repeatedcv",
                        search="grid",
                        number = 10,
                        repeats=10,
                        timingSamps = 5,
                        # seeds = c(1:101)
                        )
# Predict income using decision tree
dec_mod <- train(x=x_train,
                 y=y_train,
                    method = "rpartScore",  
                    trControl = ctrl_cv,
                    tuneGrid = expand.grid(
                      cp = seq(0,1,0.1),
                      split = c("abs", "quad"),
                      prune = c("mc", "mr")
                      )

                 )

stopCluster(cl)
```

```{r}
registerDoSEQ()
```

```{r}
# Post prediction
postResample(predict(dec_mod, x_test), y_test)
```

```{r}
prediction_tibble <- tibble("target"=y_test,
       "prediction"=predict(dec_mod, x_test))
prediction_table <- table(prediction_tibble)
cfm <- as_tibble(prediction_table)

```


```{r}
plot_confusion_matrix(cfm, 
                      target_col = "target", 
                      prediction_col = "prediction",
                      counts_col = "n")
                      
                      
```

```{r, fig.height=10, fig.width=15}
fancyRpartPlot(dec_mod$finalModel)
```


```{r}
varImp(dec_mod)
```


```{r}
ggplot(data=df, aes(x=id, y=intention_store, color=demographic_gender)) + geom_point()
```

```{r}
ggplot(data=df, aes(x=id, y=behaviour_indoors_nonhouseholders, color=demographic_gender)) + geom_point()
```

```{r}
dec_mod
```

```{r}
dec_mod$bestTune
dec_mod$finalModel
```

